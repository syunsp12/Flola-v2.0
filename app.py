import os
import json
import datetime
import pandas as pd
import streamlit as st
import plotly.express as px
import google.generativeai as genai
from supabase import create_client, Client
from dotenv import load_dotenv

# --- è¨­å®šãƒ»æ¥ç¶š ---
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not all([SUPABASE_URL, SUPABASE_KEY, GOOGLE_API_KEY]):
    st.error("ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ (.envã‚’ç¢ºèªã—ã¦ãã ã•ã„)")
    st.stop()

# Geminiè¨­å®š
genai.configure(api_key=GOOGLE_API_KEY)

# Supabaseæ¥ç¶š (ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
@st.cache_resource
def init_connection():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase = init_connection()

# --- é–¢æ•°: AIã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒªæ¨è«– ---
def predict_categories(descriptions, categories_df):
    """
    Gemini APIã‚’ä½¿ç”¨ã—ã¦ã€æ‘˜è¦ãƒªã‚¹ãƒˆã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªIDã‚’æ¨è«–ã™ã‚‹
    """
    if not descriptions:
        return {}

    # ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦AIã«æ¸¡ã™
    cat_text = ""
    for _, row in categories_df.iterrows():
        keywords = row['keywords'] if row['keywords'] else []
        cat_text += f"ID:{row['id']}, Name:{row['name']}, Keywords:{','.join(keywords)}\n"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    prompt = f"""
    ã‚ãªãŸã¯å®¶è¨ˆç°¿ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚’è¡Œã†AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®ã€Œã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆã€ã«åŸºã¥ãã€ã€Œå¯¾è±¡ã®æ‘˜è¦ï¼ˆDescriptionï¼‰ã€ã«æœ€ã‚‚é©åˆ‡ãªã€Œã‚«ãƒ†ã‚´ãƒªIDã€ã‚’æ¨æ¸¬ã—ã¦ãã ã•ã„ã€‚
    
    # ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆ
    {cat_text}
    
    # å¯¾è±¡ã®æ‘˜è¦
    {json.dumps(descriptions, ensure_ascii=False)}
    
    # åˆ¶ç´„äº‹é …
    1. å‡ºåŠ›ã¯å¿…ãšä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚Markdownè¨˜æ³•ã¯ä¸è¦ã§ã™ã€‚
    2. ç¢ºä¿¡ãŒæŒã¦ãªã„å ´åˆã¯ã€Œæœªåˆ†é¡ã€ã®IDã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
    
    # å‡ºåŠ›å½¢å¼ (JSON)
    {{
        "SUKIYA": 2,
        "AMAZON": 5
    }}
    """

    try:
        model = genai.GenerativeModel('gemini-flash-latest')
        response = model.generate_content(prompt)
        text = response.text
        
        # JSONéƒ¨åˆ†ã ã‘æŠ½å‡ºï¼ˆMarkdownã®ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆå¯¾ç­–ï¼‰
        text = text.replace("```json", "").replace("```", "").strip()
        result_dict = json.loads(text)
        return result_dict
    except Exception as e:
        st.error(f"AIæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Flola v2", layout="wide")
st.title("ğŸ’° Flola v2 Asset Manager")

# ã‚¿ãƒ–ä½œæˆ
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Dashboard", "âœ… Approval (æ‰¿èª)", "â• Input (å…¥åŠ›)"])

# ==========================================
# Tab 1: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (å¯è¦–åŒ–)
# ==========================================
with tab1:
    st.header("è³‡ç”£ã‚µãƒãƒª")
    
    try:
        response = supabase.table("assets").select("*").execute()
        assets_df = pd.DataFrame(response.data)

        if not assets_df.empty:
            latest_date = assets_df['record_date'].max()
            current_assets = assets_df[assets_df['record_date'] == latest_date]
            
            total_assets = current_assets['market_value'].sum()
            st.metric("ç·è³‡ç”£", f"Â¥{total_assets:,}", f"åŸºæº–æ—¥: {latest_date}")

            fig = px.pie(current_assets, values='market_value', names='institution', title='ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª')
            st.plotly_chart(fig, use_container_width=True)
            
            st.dataframe(current_assets[['record_date', 'institution', 'name', 'market_value']])
        else:
            st.info("è³‡ç”£ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã€ŒInputã€ã‚¿ãƒ–ã‹ã‚‰å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

# ==========================================
# Tab 2: ãƒ‡ãƒ¼ã‚¿æ‰¿èª (Human-in-the-Loop)
# ==========================================
with tab2:
    st.header("æœªæ‰¿èªãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
    
    # 1. ãƒã‚¹ã‚¿å–å¾—
    cat_res = supabase.table("categories").select("*").execute()
    categories_df = pd.DataFrame(cat_res.data)
    
    # 2. æœªæ‰¿èªãƒ‡ãƒ¼ã‚¿å–å¾—
    response = supabase.table("transactions").select("*").eq("status", "pending").order("date", desc=True).execute()
    pending_data = response.data

    if pending_data:
        df = pd.DataFrame(pending_data)
        
        # æ—¥ä»˜å‹ã®å¤‰æ›
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date']).dt.date

        # --- AIè‡ªå‹•ææ¡ˆãƒœã‚¿ãƒ³ ---
        col_ai, _ = st.columns([1, 3])
        with col_ai:
            if st.button("ğŸ¤– AIã§ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•ææ¡ˆ", type="primary"):
                with st.spinner("AIãŒæ€è€ƒä¸­..."):
                    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ‘˜è¦ã ã‘æŠ½å‡ºã—ã¦APIç¯€ç´„
                    unique_descriptions = df['description'].unique().tolist()
                    ai_suggestions = predict_categories(unique_descriptions, categories_df)
                    
                    if ai_suggestions:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«é©ç”¨
                        # descriptionã‚’ã‚­ãƒ¼ã«ã—ã¦ category_id ã‚’ãƒãƒƒãƒ—ã™ã‚‹
                        df['category_id'] = df['description'].map(ai_suggestions).fillna(df['category_id'])
                        st.toast("AIã«ã‚ˆã‚‹ææ¡ˆã‚’é©ç”¨ã—ã¾ã—ãŸï¼ç¢ºèªã—ã¦æ‰¿èªã—ã¦ãã ã•ã„ã€‚", icon="âœ¨")
                    else:
                        st.warning("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.divider()

        # --- ãƒ‡ãƒ¼ã‚¿ç·¨é›†ã‚¨ãƒ‡ã‚£ã‚¿ ---
        df['approve'] = False
        
        # ã‚«ãƒ†ã‚´ãƒªé¸æŠè‚¢ã‚’è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ã«è¡¨ç¤ºåã‚’åŠ å·¥ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã ãŒã€
        # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«IDå…¥åŠ›ã¾ãŸã¯æ•°å€¤ã¨ã—ã¦æ‰±ã†
        # (Streamlitã®å°†æ¥ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§SelectBoxãŒä½¿ã„ã‚„ã™ããªã‚‹ã®ã‚’æœŸå¾…)
        
        edited_df = st.data_editor(
            df,
            column_config={
                "approve": st.column_config.CheckboxColumn("æ‰¿èª", default=False),
                "category_id": st.column_config.NumberColumn("ã‚«ãƒ†ã‚´ãƒªID", help="ãƒã‚¹ã‚¿IDã‚’å…¥åŠ›"),
                "date": st.column_config.DateColumn("æ—¥ä»˜"),
                "amount": st.column_config.NumberColumn("é‡‘é¡", format="Â¥%d"),
                "description": st.column_config.TextColumn("æ‘˜è¦"),
            },
            hide_index=True,
            use_container_width=True,
            key="editor"
        )
        
        # --- ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ã®å‚ç…§è¡¨ç¤º ---
        with st.expander("â„¹ï¸ ã‚«ãƒ†ã‚´ãƒªIDä¸€è¦§ã‚’ç¢ºèªã™ã‚‹"):
            st.dataframe(categories_df[['id', 'name', 'keywords']], hide_index=True)

        # --- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ ---
        col1, col2 = st.columns(2)
        with col1:
            if st.button("é¸æŠã—ãŸé …ç›®ã‚’æ‰¿èª (Save)", type="primary"):
                to_confirm = edited_df[edited_df['approve'] == True]
                
                if not to_confirm.empty:
                    count = 0
                    for index, row in to_confirm.iterrows():
                        cat_id = row['category_id']
                        # NaNãƒã‚§ãƒƒã‚¯
                        if pd.isna(cat_id):
                            cat_id = None
                        else:
                            cat_id = int(cat_id)

                        update_data = {
                            "status": "confirmed",
                            "description": row['description'],
                            "category_id": cat_id,
                            "date": str(row['date'])
                        }
                        supabase.table("transactions").update(update_data).eq("id", row['id']).execute()
                        count += 1
                    
                    st.success(f"{count} ä»¶ã‚’æ‰¿èªã—ã¾ã—ãŸï¼")
                    st.rerun()
                else:
                    st.warning("æ‰¿èªã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        
        with col2:
            if st.button("é¸æŠã—ãŸé …ç›®ã‚’é™¤å¤– (Ignore)"):
                to_ignore = edited_df[edited_df['approve'] == True]
                if not to_ignore.empty:
                    for index, row in to_ignore.iterrows():
                        supabase.table("transactions").update({"status": "ignore"}).eq("id", row['id']).execute()
                    st.success("é™¤å¤–ã—ã¾ã—ãŸã€‚")
                    st.rerun()

    else:
        st.success("æœªæ‰¿èªãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ ğŸ‰")

# ==========================================
# Tab 3: æ‰‹å‹•å…¥åŠ› (Input)
# ==========================================
with tab3:
    st.header("è³‡ç”£æ®‹é«˜ã®æ‰‹å‹•æ›´æ–°")
    
    with st.form("asset_input_form"):
        col1, col2 = st.columns(2)
        with col1:
            input_date = st.date_input("åŸºæº–æ—¥", datetime.date.today())
            institution = st.text_input("é‡‘èæ©Ÿé–¢å", placeholder="ä¾‹: ä¸‰äº•ä½å‹éŠ€è¡Œ")
        with col2:
            name = st.text_input("å£åº§ãƒ»å•†å“å", placeholder="ä¾‹: æ™®é€šé é‡‘")
            value = st.number_input("æ®‹é«˜ (å††)", min_value=0, step=1000)
            
        submitted = st.form_submit_button("ä¿å­˜")
        
        if submitted:
            if institution and value is not None:
                data = {
                    "record_date": input_date.isoformat(),
                    "institution": institution,
                    "name": name if name else "ä¸€èˆ¬",
                    "market_value": int(value),
                    "source": "manual_input"
                }
                
                try:
                    supabase.table("assets").upsert(
                        data, on_conflict="record_date, institution, name, source"
                    ).execute()
                    st.success("ä¿å­˜ã—ã¾ã—ãŸï¼")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("é‡‘èæ©Ÿé–¢åã¨æ®‹é«˜ã¯å¿…é ˆã§ã™ã€‚")